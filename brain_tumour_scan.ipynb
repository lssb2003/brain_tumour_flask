{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3148b8-a9db-4f02-8158-3dde826cf345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 10.2850, Accuracy: 62.06%\n",
      "Validation Loss: 1.4371, Validation Accuracy: 61.26%\n",
      "Epoch [2/20], Loss: 4.5632, Accuracy: 67.98%\n",
      "Validation Loss: 1.1923, Validation Accuracy: 71.54%\n",
      "Epoch [3/20], Loss: 3.0700, Accuracy: 67.98%\n",
      "Validation Loss: 1.7469, Validation Accuracy: 67.59%\n",
      "Epoch [4/20], Loss: 2.4528, Accuracy: 69.96%\n",
      "Validation Loss: 1.0248, Validation Accuracy: 73.52%\n",
      "Epoch [5/20], Loss: 1.8629, Accuracy: 68.38%\n",
      "Validation Loss: 1.7615, Validation Accuracy: 67.59%\n",
      "Epoch [6/20], Loss: 1.0623, Accuracy: 75.49%\n",
      "Validation Loss: 0.4279, Validation Accuracy: 84.58%\n",
      "Epoch [7/20], Loss: 0.5972, Accuracy: 80.24%\n",
      "Validation Loss: 0.4440, Validation Accuracy: 85.77%\n",
      "Epoch [8/20], Loss: 0.5165, Accuracy: 83.00%\n",
      "Validation Loss: 0.3219, Validation Accuracy: 87.75%\n",
      "Epoch [9/20], Loss: 0.4312, Accuracy: 77.87%\n",
      "Validation Loss: 0.3518, Validation Accuracy: 84.19%\n",
      "Epoch [10/20], Loss: 0.3860, Accuracy: 86.17%\n",
      "Validation Loss: 0.2979, Validation Accuracy: 87.75%\n",
      "Epoch [11/20], Loss: 0.3169, Accuracy: 85.38%\n",
      "Validation Loss: 0.2847, Validation Accuracy: 86.56%\n",
      "Epoch [12/20], Loss: 0.3595, Accuracy: 85.38%\n",
      "Validation Loss: 0.2626, Validation Accuracy: 90.12%\n",
      "Epoch [13/20], Loss: 0.3482, Accuracy: 85.38%\n",
      "Validation Loss: 0.2486, Validation Accuracy: 90.12%\n",
      "Epoch [14/20], Loss: 0.2967, Accuracy: 88.14%\n",
      "Validation Loss: 0.2061, Validation Accuracy: 92.49%\n",
      "Epoch [15/20], Loss: 0.2499, Accuracy: 86.96%\n",
      "Validation Loss: 0.1986, Validation Accuracy: 94.07%\n",
      "Epoch [16/20], Loss: 0.2876, Accuracy: 89.33%\n",
      "Validation Loss: 0.2366, Validation Accuracy: 88.93%\n",
      "Epoch [17/20], Loss: 0.2801, Accuracy: 88.93%\n",
      "Validation Loss: 0.1892, Validation Accuracy: 92.89%\n",
      "Epoch [18/20], Loss: 0.2434, Accuracy: 90.91%\n",
      "Validation Loss: 0.1671, Validation Accuracy: 95.26%\n",
      "Epoch [19/20], Loss: 0.2227, Accuracy: 91.70%\n",
      "Validation Loss: 0.1709, Validation Accuracy: 93.28%\n",
      "Epoch [20/20], Loss: 0.1931, Accuracy: 91.70%\n",
      "Validation Loss: 0.1359, Validation Accuracy: 96.05%\n",
      "Best Validation Accuracy: 96.05%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Define a more complex CNN model with BatchNorm and Dropout\n",
    "class EnhancedBrainTumorCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedBrainTumorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Data augmentation and preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Ensure the image is in RGB format\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip for data augmentation\n",
    "    transforms.RandomRotation(20),  # Random rotation for data augmentation\n",
    "    transforms.Resize((128, 128)),  # Resize to match model input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize as per the model requirements\n",
    "])\n",
    "\n",
    "# Dataset class\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load images and labels from the folder structure\n",
    "        for label in ['yes', 'no']:\n",
    "            folder_path = os.path.join(image_folder, label)\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                self.images.append(os.path.join(folder_path, image_name))\n",
    "                self.labels.append(1 if label == 'yes' else 0)  # Label 1 for tumor, 0 for no tumor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Paths to the image directories\n",
    "train_image_folder = 'datasets/brain_tumor_dataset'  # This is where your images are stored\n",
    "valid_image_folder = 'datasets/brain_tumor_dataset'\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = BrainTumorDataset(image_folder=train_image_folder, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "valid_dataset = BrainTumorDataset(image_folder=valid_image_folder, transform=transform)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load model\n",
    "model = EnhancedBrainTumorCNN()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Scheduler (reduce the learning rate if the validation loss plateaus)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, valid_loader, num_epochs=10):\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0\n",
    "        correct, total = 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate average loss and accuracy for this epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(valid_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        # Check if this is the best model based on validation accuracy\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "# Train the model\n",
    "train_model(model, train_loader, valid_loader, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf54d4-c920-49e6-bd83-8b95ac9b09e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5d272-7fad-4a7b-b99c-dd3af42d5a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
